% Encoding: UTF-8


@STRING{a = {Automatica}}

@STRING{acc = {{IEEE} American Control Conference}}

@STRING{ap = {Academic Press}}

@STRING{assp = {{IEEE} Transactions on Acoustics, Speech and Signal Processing}}

@STRING{aw = {Addison-Wesley Publishing Company}}

@STRING{bh = {Birkh{\"a}user Verlag}}

@STRING{c = {Cambridge University Press}}

@STRING{collection_nips = {Advances in Neural Information Processing Systems ({NIPS})}}
@String{conf_acc                 = {American Control Conference ({ACC})}}

@STRING{conf_aistats = {International Conference on Artificial Intelligence and Statistics}}

@STRING{conf_cdc = {{IEEE} Conference on Decision and Control ({CDC})}}

@STRING{conf_fusion = {International Conference on Information Fusion ({FUSION})}}

@STRING{conf_icassp = {{IEEE} International Conference on Acoustics, Speech and Signal Processing
	({ICASSP})}}

@STRING{conf_iccv = {{IEEE} International Conference on Computer Vision ({ICCV})}}

@STRING{conf_icml = {International Conference on Machine Learning}}

@STRING{conf_icra = {{IEEE} International Conference on Robotics and Automation ({ICRA})}}

@STRING{conf_ifacwc = {{IFAC} World Congress}}

@STRING{conf_mlsp = {{IEEE} International Workshop on Machine Learning for Signal Processing ({MLSP})}}

@STRING{conf_nips = {Conference on Neural Information Processing Systems ({NIPS})}}

@STRING{conf_safeprocess = {{IFAC} Symposium on Fault Detection, Supervision and Safety of Technical
	Processes (SafeProcess)}}

@STRING{conf_ssp = {{IEEE} Workshop on Statistical Signal Processing ({SSP})}}

@STRING{conf_sysid = {{IFAC} Symposium on System Identification ({SYSID})}}

@STRING{conf_uai = {Conference on Uncertainty in Artificial Intelligence ({UAI})}}

@STRING{cst = {{IEEE} Transactions on Control System Technology}}

@STRING{eusipco = {European Signal Processing Conference ({EUSIPCO})}}

@STRING{iccv = {{IEEE} International Conference on Computer Vision ({ICCV})}}

@STRING{ieeer = {{IEEE} Transactions on Robotics}}

@STRING{ieeera = {{IEEE} Transactions on Robotics and Automation}}

@STRING{ijc = {International Journal of Control}}

@STRING{ISYname = {Department of Electrical Engineering, Link\"oping University}}

@STRING{it = {{IEEE} Transactions on Information Theory}}

@STRING{jfr = {Journal of Field Robotics}}

@STRING{jour_aap = {The Annals of Applied Probability}}

@STRING{jour_ac = {{IEEE} Transactions on Automatic Control}}

@STRING{jour_ams = {Annals of Mathematical Statistics}}

@STRING{jour_as = {The Annals of Statistics}}

@STRING{jour_automatica = {Automatica}}

@STRING{jour_bernoulli = {Bernoulli}}

@STRING{jour_biometrika = {Biometrika}}

@STRING{jour_cst = {{IEEE} Transactions on Control Systems Technology}}

@STRING{jour_fntml = {Foundations and Trends in Machine Learning}}

@STRING{jour_jasa = {Journal of the American Statistical Association}}

@STRING{jour_jcgs = {Journal of Computational and Graphical Statistics}}

@STRING{jour_jmlr = {Journal of Machine Learning Research}}

@STRING{jour_jrssb = {Journal of the Royal Statistical Society: Series {B}}}

@STRING{jour_jrssc = {Journal of the Royal Statistical Society: Series {C}}}

@STRING{jour_proceedingsieee = {Proceedings of the {IEEE}}}

@STRING{jour_sjos = {Scandinavian Journal of Statistics}}

@STRING{jour_statcomp = {Statistics and Computing}}

@STRING{jour_tit = {{IEEE} Transactions on Information Theory}}

@STRING{jour_tsp = {{IEEE} Transactions on Signal Processing}}

@STRING{Lic = {Licentiate {T}hesis {N}o~}}

@STRING{LiU_addess = {{SE}-581 83 {L}ink\"oping, {S}weden}}

@STRING{LiU_PhD_School = {Link\"oping {S}tudies in {S}cience and {T}echnology}}

@STRING{MSc = {Master's {T}hesis {N}o~}}

@STRING{pami = {{IEEE} Transactions on Pattern Analysis and Machine Intelligence}}

@STRING{PhDNo = {PhD thesis {N}o~}}

@STRING{pp = {Pergamon Press}}

@STRING{PROC = {Proceedings of the }}

@STRING{publisher_ap = {Academic Press}}

@STRING{publisher_artech = {Artech House}}

@STRING{publisher_cambridgepress = {Cambridge University Press}}

@STRING{publisher_jw = {John Wiley \& Sons}}

@STRING{publisher_mitpress = {{MIT} Press}}

@STRING{publisher_oxfordpress = {Oxford University Press}}

@STRING{publisher_pearson = {Pearson}}

@STRING{publisher_ph = {Prentice Hall}}

@STRING{publisher_springer = {Springer}}

@STRING{publisher_springverlag = {Springer-Verlag}}

@STRING{sae = {SAE Society of Automotive Engineers}}

@STRING{uai = {Conference on Uncertainty in Artificial Intelligence ({UAI})}}



@Misc{LindholmL:2019,
  author       = {Andreas Lindholm and Fredrik Lindsten},
  title        = {Learning dynamical systems with particle stochastic approximation {EM}},
  howpublished = {arXiv.org, arXiv:1806.09548},
  url = {https://arxiv.org/abs/1806.09548},
  year         = {2019},
  abstract = {We present the particle stochastic approximation EM (PSAEM) algorithm for learning of dynamical systems. The method builds on the EM algorithm, an iterative procedure for maximum likelihood inference in latent variable models. By combining stochastic approximation EM and particle Gibbs with ancestor sampling (PGAS), PSAEM obtains superior computational performance and convergence properties compared to plain particle-smoothing-based approximations of the EM algorithm. PSAEM can be used for plain maximum likelihood inference as well as for empirical Bayes learning of hyperparameters. Specifically, the latter point means that existing PGAS implementations easily can be extended with PSAEM to estimate hyperparameters at almost no extra computational cost. We discuss the convergence properties of the algorithm, and demonstrate it on several signal processing applications.},
  pid      = {WP2},
}

@Misc{AlenlovDL:2016,
  author       = {Johan Alenlöv and Arnaud Doucet and Fredrik Lindsten},
  title        = {Pseudo-Marginal {H}amiltonian {M}onte {C}arlo},
  howpublished = {arXiv.org, arXiv:1607.02516},
  url = {https://arxiv.org/abs/1607.02516},
  year         = {2019},
  abstract     = {Bayesian inference in the presence of an intractable likelihood function is computationally challenging. When following a Markov chain Monte Carlo (MCMC) approach to approximate the posterior distribution in this context, one typically either uses MCMC schemes which target the joint posterior of the parameters and some auxiliary latent variables, or pseudo-marginal Metropolis--Hastings (MH) schemes. The latter mimic a MH algorithm targeting the marginal posterior of the parameters by approximating unbiasedly the intractable likelihood. However, in scenarios where the parameters and auxiliary variables are strongly correlated under the posterior and/or this posterior is multimodal, Gibbs sampling or Hamiltonian Monte Carlo (HMC) will perform poorly and the pseudo-marginal MH algorithm, as any other MH scheme, will be inefficient for high dimensional parameters. We propose here an original MCMC algorithm, termed pseudo-marginal HMC, which combines the advantages of both HMC and pseudo-marginal schemes. Specifically, the pseudo-marginal HMC method is controlled by a precision parameter N, controlling the approximation of the likelihood and, for any N, it samples the marginal posterior of the parameters. Additionally, as N tends to infinity, its sample trajectories and acceptance probability converge to those of an ideal, but intractable, HMC algorithm which would have access to the marginal posterior of parameters and its gradient. We demonstrate through experiments that pseudo-marginal HMC can outperform significantly both standard HMC and pseudo-marginal MH schemes.},
  pid      = {WP1},
}




@Book{LindholmWLS:2020,
  author   = {Andreas Lindholm and Niklas Wahlström and Fredrik Lindsten and Thomas B. Schön},
  title    = {Supervised Machine Learning},
  year     = {Draft 2020},
  url      = {http://smlbook.org/},
  pid      = {B1},
  note     = {Draft},
}



@Article{NaessethLS:2019a,
  author   = {Christian A. Naesseth and Fredrik Lindsten and Thomas B. Sch\"on},
  title    = {Elements of Sequential {M}onte {C}arlo},
  journal  = jour_fntml,
  year     = {2019},
  volume   = {12},
  number   = {3},
  pages    = {307--392},
  abstract = {A core problem in statistics and probabilistic machine learning is to compute probability distributions and expectations. This is the fundamental problem of Bayesian statistics and machine learning, which frames all inference as expectations with respect to the posterior distribution. The key challenge is to approximate these intractable expectations. In this tutorial, we review sequential Monte Carlo (SMC), a random-sampling-based class of methods for approximate inference. First, we explain the basics of SMC, discuss practical issues, and review theoretical results. We then examine two of the main user design choices: the proposal distributions and the so called intermediate target distributions. We review recent results on how variational inference and amortization can be used to learn efficient proposals and target distributions. Next, we discuss the SMC estimate of the normalizing constant, how this can be used for pseudo-marginal inference and inference evaluation. Throughout the tutorial we illustrate the use of SMC on various models commonly used in machine learning, such as stochastic recurrent neural networks, probabilistic graphical models, and probabilistic programs.},
  pid  = {M2},
  doi      = {10.1561/2200000074},
  url      = {https://arxiv.org/abs/1903.04797},
}

@Article{LindstenS:2013,
  author    = {Lindsten, Fredrik and Sch\"on, Thomas B.},
  title     = {Backward simulation methods for {M}onte {C}arlo statistical inference},
  journal   = jour_fntml,
  year      = {2013},
  volume    = {6},
  number    = {1},
  pages     = {1--143},
  doi = {10.1561/2200000045},
  abstract = {Monte Carlo methods, in particular those based on Markov chains and on interacting particle systems, are by now tools that are routinely used in machine learning. These methods have had a profound impact on statistical inference in a wide range of application areas where probabilistic models are used. Moreover, there are many algorithms in machine learning which are based on the idea of processing the data sequentially, first in the forward direction and then in the backward direction. In this tutorial, we will review a branch of Monte Carlo methods based on the forward–backward idea, referred to as backward simulators. These methods are useful for learning and inference in probabilistic models containing latent stochastic processes. The theory and practice of backward simulation algorithms have undergone a significant development in recent years and the algorithms keep finding new applications. The foundation for these methods is sequential Monte Carlo (SMC). SMC-based backward simulators are capable of addressing smoothing problems in sequential latent variable models, such as general, nonlinear/non-Gaussian state-space models (SSMs). However, we will also clearly show that the underlying backward simulation idea is by no means restricted to SSMs. Furthermore, backward simulation plays an important role in recent developments of Markov chain Monte Carlo (MCMC) methods. Particle MCMC is a systematic way of using SMC within MCMC. In this framework, backward simulation gives us a way to significantly improve the performance of the samplers. We review and discuss several related backward-simulation-based methods for state inference as well as learning of static parameters, both using a frequentistic and a Bayesian approach.},
  pid   = {M1},
}



@Article{NaessethLS:2019,
  author  = {Christian A. Naesseth and Fredrik Lindsten and Thomas B. Schön},
  title   = {High-dimensional Filtering using Nested Sequential {M}onte {C}arlo},
  journal = jour_tsp,
  year    = {2019},
  volume  = {67},
  number  = {16},
  pages   = {4177--4188},
  doi     = {10.1109/TSP.2019.2926035},
  url     = {https://arxiv.org/abs/1612.09162},
  abstract = {Sequential Monte Carlo (SMC) methods comprise one of the most successful approaches to approximate Bayesian filtering. However, SMC without good proposal distributions struggle in high dimensions. We propose nested sequential Monte Carlo (NSMC), a methodology that generalises the SMC framework by requiring only approximate, properly weighted, samples from the SMC proposal distribution, while still resulting in a correct SMC algorithm. This way we can exactly approximate the locally optimal proposal, and extend the class of models for which we can perform efficient inference using SMC. We show improved accuracy over other state-of-the-art methods on several spatio-temporal state space models.},
  pid = {J14},
}

@Article{RisuleoLH:2019,
  author  = {Riccardo S. Risuleo and Fredrik Lindsten and Håkan Hjalmarsson},
  title   = {Bayesian nonparametric identification of {W}iener systems},
  journal = {Automatica},
  year    = {2019},
  volume  = {108},
  note    = {Brief paper},
  doi = {10.1016/j.automatica.2019.06.032},
  abstract = {We propose a nonparametric approach for the identification of Wiener systems. We model the impulse response of the linear block and the static nonlinearity using Gaussian processes. The hyperparameters of the Gaussian processes are estimated using an iterative algorithm based on stochastic approximation expectation–maximization. In the iterations, we use elliptical slice sampling to approximate the posterior distribution of the impulse response and update the hyperparameter estimates. The same sampling is finally used to sample the posterior distribution and to compute point estimates. We compare the proposed approach with a parametric approach and a semi-parametric approach. In particular, we show that the proposed method has an advantage when a parametric model for the system is not readily available.},
  pid = {J13},
}

@Article{JacobLS:2019,
  author  = {Pierre E. Jacob and Fredrik Lindsten and Thomas B. Schön},
  title   = {Smoothing with Couplings of Conditional Particle Filters},
  journal = jour_jasa,
  year    = {2019},
  pages   = {721--729},
  volume  = {115},
  number  = {530},
  abstract = {In state–space models, smoothing refers to the task of estimating a latent stochastic process given noisy measurements related to the process. We propose an unbiased estimator of smoothing expectations. The lack-of-bias property has methodological benefits: independent estimators can be generated in parallel, and CI can be constructed from the central limit theorem to quantify the approximation error. To design unbiased estimators, we combine a generic debiasing technique for Markov chains, with a Markov chain Monte Carlo algorithm for smoothing. The resulting procedure is widely applicable and we show in numerical experiments that the removal of the bias comes at a manageable increase in variance. We establish the validity of the proposed estimators under mild assumptions. Numerical experiments are provided on toy models, including a setting of highly informative observations, and for a realistic Lotka–Volterra model with an intractable transition density.},
  pid = {J12},
  doi     = {https://doi.org/10.1080/01621459.2018.1548856},
  url = {https://arxiv.org/abs/1701.02002},
}

@Article{CalafatWLWF:2018,
  author  = {Francisco M. Calafat and Thomas Wahl and Fredrik Lindsten and Joanne Williams and Eleanor Frajka-Williams},
  title   = {Coherent modulation of the sea-level annual cycle in the {U}nited {S}tates by {A}tlantic {R}ossby waves},
  journal = {Nature Communications},
  year    = {2018},
  volume  = {9},
  number  = {2571},
  doi = {10.1038/s41467-018-04898-y},
  abstract = {Changes in the sea-level annual cycle (SLAC) can have profound impacts on coastal areas, including increased flooding risk and ecosystem alteration, yet little is known about the magnitude and drivers of such changes. Here we show, using novel Bayesian methods, that there are significant decadal fluctuations in the amplitude of the SLAC along the United States Gulf and Southeast coasts, including an extreme event in 2008–2009 that is likely (probability ≥68%) unprecedented in the tide-gauge record. Such fluctuations are coherent along the coast but decoupled from deep-ocean changes. Through the use of numerical and analytical ocean models, we show that the primary driver of these fluctuations involves incident Rossby waves that generate fast western-boundary waves. These Rossby waves project onto the basin-wide upper mid-ocean transport (top 1000 m) leading to a link with the SLAC, wherein larger SLAC amplitudes coincide with enhanced transport variability.},
  pid = {J11},
}

@Article{SchonSML:2018,
  author  = {Thomas B. Schön and Andreas Svensson and Lawrence Murray and Fredrik Lindsten},
  title   = {Probabilistic learning of nonlinear dynamical systems using sequential {M}onte {C}arlo},
  journal = {Mechanical Systems and Signal Processing},
  year    = {2018},
  volume  = {104},
  pages   = {866--883},
  abstract = {Probabilistic modeling provides the capability to represent and manipulate uncertainty in data, models, predictions and decisions. We are concerned with the problem of learning probabilistic models of dynamical systems from measured data. Specifically, we consider learning of probabilistic nonlinear state-space models. There is no closed-form solution available for this problem, implying that we are forced to use approximations. In this tutorial we will provide a self-contained introduction to one of the state-of-the-art methods---the particle Metropolis--Hastings algorithm---which has proven to offer a practical approximation. This is a Monte Carlo based method, where the particle filter is used to guide a Markov chain Monte Carlo method through the parameter space. One of the key merits of the particle Metropolis--Hastings algorithm is that it is guaranteed to converge to the "true solution" under mild assumptions, despite being based on a particle filter with only a finite number of particles. We will also provide a motivating numerical example illustrating the method using a modeling language tailored for sequential Monte Carlo methods. The intention of modeling languages of this kind is to open up the power of sophisticated Monte Carlo methods---including particle Metropolis--Hastings---to a large group of users without requiring them to know all the underlying mathematical details.},
  url = {https://arxiv.org/abs/1703.02419},
  pid = {J10},
}

@Article{SvenssonSL:2018,
  author  = {Andreas Svensson and Thomas B. Schön and Fredrik Lindsten},
  title   = {Learning of state-space models with highly informative observations: a tempered Sequential {M}onte {C}arlo solution},
  journal = {Mechanical Systems and Signal Processing},
  year    = {2018},
  volume  = {104},
  pages   = {915--928},
  url = {https://arxiv.org/abs/1702.01618},
  abstract = {Probabilistic (or Bayesian) modeling and learning offers interesting possibilities for systematic representation of uncertainty using probability theory. However, probabilistic learning often leads to computationally challenging problems. Some problems of this type that were previously intractable can now be solved on standard personal computers thanks to recent advances in Monte Carlo methods. In particular, for learning of unknown parameters in nonlinear state-space models, methods based on the particle filter (a Monte Carlo method) have proven very useful. A notoriously challenging problem, however, still occurs when the observations in the state-space model are highly informative, i.e. when there is very little or no measurement noise present, relative to the amount of process noise. The particle filter will then struggle in estimating one of the basic components for probabilistic learning, namely the likelihood p(data|parameters). To this end we suggest an algorithm which initially assumes that there is substantial amount of artificial measurement noise present. The variance of this noise is sequentially decreased in an adaptive fashion such that we, in the end, recover the original problem or possibly a very close approximation of it. The main component in our algorithm is a sequential Monte Carlo (SMC) sampler, which gives our proposed method a clear resemblance to the SMC^2 method. Another natural link is also made to the ideas underlying the approximate Bayesian computation (ABC). We illustrate it with numerical examples, and in particular show promising results for a challenging Wiener-Hammerstein benchmark problem.},
  pid = {J9},
}


@Article{SinghLM:2017,
  author  = {Singh, Sumeetpal S. and Lindsten, Fredrik and Moulines, Eric},
  title   = {Blocking Strategies and Stability of Particle {G}ibbs Samplers},
  journal = {Biometrika},
  year    = {2017},
  volume  = {104},
  number  = {4},
  pages   = {953--969},
  url = {https://arxiv.org/abs/1509.08362},
  doi = {10.1093/biomet/asx051},
  abstract = {Sampling from the conditional (or posterior) probability distribution of the latent states of a Hidden Markov Model, given the realization of the observed process, is a non-trivial problem in the context of Markov Chain Monte Carlo. To do this Andrieu et al. (2010) constructed a Markov kernel which leaves this conditional distribution invariant using a Particle Filter. From a practitioner's point of view, this Markov kernel attempts to mimic the act of sampling all the latent state variables as one block from the posterior distribution but for models where exact simulation is not possible. There are some recent theoretical results that establish the uniform ergodicity of this Markov kernel and that the mixing rate does not diminish provided the number of particles grows at least linearly with the number of latent states in the posterior. This gives rise to a cost, per application of the kernel, that is quadratic in the number of latent states which could be prohibitive for long observation sequences. We seek to answer an obvious but important question: is there a different implementation with a cost per-iteration that grows linearly with the number of latent states, but which is still stable in the sense that its mixing rate does not deteriorate? We address this problem using blocking strategies, which are easily parallelizable, and prove stability of the resulting sampler.},
  pid = {J8},
}

@Article{LindstenJNKSAB:2017,
  author  = {Lindsten, Fredrik and Johansen, Adam and Naesseth, Christian A. and Kirkpatrick, Brent and Sch\"on, Thomas B. and Aston, John and Bouchard-C\^ot\'e, Alexandre},
  title   = {Divide-and-Conquer with Sequential {M}onte {C}arlo},
  journal = jour_jcgs,
  year    = {2017},
  volume  = {26},
  number  = {2},
  pages   = {445--458},
  url = {https://arxiv.org/abs/1406.4993},
  doi = {10.1080/10618600.2016.1237363},
  abstract = {We propose a novel class of Sequential Monte Carlo (SMC) algorithms, appropriate for inference in probabilistic graphical models. This class of algorithms adopts a divide-and-conquer approach based upon an auxiliary tree-structured decomposition of the model of interest, turning the overall inferential task into a collection of recursively solved sub-problems. The proposed method is applicable to a broad class of probabilistic graphical models, including models with loops. Unlike a standard SMC sampler, the proposed Divide-and-Conquer SMC employs multiple independent populations of weighted particles, which are resampled, merged, and propagated as the method progresses. We illustrate empirically that this approach can outperform standard methods in terms of the accuracy of the posterior expectation and marginal likelihood approximations. Divide-and-Conquer SMC also opens up novel parallel implementation options and the possibility of concentrating the computational effort on the most challenging sub-problems. We demonstrate its performance on a Markov random field and on a hierarchical logistic regression problem.},
  pid = {J7},
}

@Article{LindstenBSSG:2016,
  author  = {Fredrik Lindsten and Pete Bunch and S. Särkkä and Thomas B. Schön and Simon J. Godsill},
  title   = {Rao-{B}lackwellized particle smoothers for conditionally linear {G}aussian models},
  journal = {IEEE Journal of Selected Topics in Signal Processing},
  year    = {2016},
  volume  = {10},
  number  = {2},
  pages   = {353--365},
  url = {https://arxiv.org/abs/1505.06357},
  abstract = {Sequential Monte Carlo (SMC) methods, such as the particle filter, are by now one of the standard computational techniques for addressing the filtering problem in general state-space models. However, many applications require post-processing of data offline. In such scenarios the smoothing problem--in which all the available data is used to compute state estimates--is of central interest. We consider the smoothing problem for a class of conditionally linear Gaussian models. We present a forward-backward-type Rao-Blackwellized particle smoother (RBPS) that is able to exploit the tractable substructure present in these models. Akin to the well known Rao-Blackwellized particle filter, the proposed RBPS marginalizes out a conditionally tractable subset of state variables, effectively making use of SMC only for the "intractable part" of the model. Compared to existing RBPS, two key features of the proposed method are: (i) it does not require structural approximations of the model, and (ii) the aforementioned marginalization is done both in the forward direction and in the backward direction.},
  pid = {J6},
}

@Article{LindstenDM:2015,
  author    = {Lindsten, Fredrik and Douc, Randal and Moulines, Eric},
  title     = {Uniform ergodicity of the Particle {G}ibbs sampler},
  journal   = jour_sjos,
  year      = {2015},
  volume    = {42},
  number    = {3},
  pages     = {775--797},
  pid   = {J5},
  doi       = {10.1111/sjos.12136},
  url = {https://arxiv.org/abs/1401.0683},
  abstract = {The particle Gibbs (PG) sampler is a systematic way of using a particle filter within Markov chain Monte Carlo (MCMC). This results in an off-the-shelf Markov kernel on the space of state trajectories, which can be used to simulate from the full joint smoothing distribution for a state space model in an MCMC scheme. We show that the PG Markov kernel is uniformly ergodic under rather general assumptions, that we will carefully review and discuss. In particular, we provide an explicit rate of convergence which reveals that: (i) for fixed number of data points, the convergence rate can be made arbitrarily good by increasing the number of particles, and (ii) under general mixing assumptions, the convergence rate can be kept constant by increasing the number of particles superlinearly with the number of observations. We illustrate the applicability of our result by studying in detail two common state space models with non-compact state spaces.},
}

@Article{OezkanLFG:2015,
  author  = {{\"O}zkan, Emre and Lindsten, Fredrik and Fritsche, Carsten and Gustafsson, Fredrik},
  title   = {Recursive maximum likelihood identification of jump {M}arkov nonlinear systems},
  journal = jour_tsp,
  year    = {2015},
  volume  = {63},
  number  = {3},
  pages   = {754--765},
  url  = {https://arxiv.org/abs/1312.0781},
  abstract = {In this contribution, we present an online method for joint state and parameter estimation in jump Markov non-linear systems (JMNLS). State inference is enabled via the use of particle filters which makes the method applicable to a wide range of non-linear models. To exploit the inherent structure of JMNLS, we design a Rao-Blackwellized particle filter (RBPF) where the discrete mode is marginalized out analytically. This results in an efficient implementation of the algorithm and reduces the estimation error variance. The proposed RBPF is then used to compute, recursively in time, smoothed estimates of complete data sufficient statistics. Together with the online expectation maximization algorithm, this enables recursive identification of unknown model parameters. The performance of the method is illustrated in simulations and on a localization problem in wireless networks using real data.},
  pid = {J4},
}

@Article{DahlinLS:2015,
  author  = {Dahlin, Johan and Lindsten, Fredrik and Sch\"on, Thomas B.},
  title   = {Particle {M}etropolis-{H}astings using gradient and {H}essian information},
  journal = jour_statcomp,
  year    = {2015},
  volume  = {25},
  number  = {1},
  pages   = {81--92},
  url = {https://arxiv.org/abs/1311.0686},
  abstract = {Particle Metropolis-Hastings (PMH) allows for Bayesian parameter inference in nonlinear state space models by combining Markov chain Monte Carlo (MCMC) and particle filtering. The latter is used to estimate the intractable likelihood. In its original formulation, PMH makes use of a marginal MCMC proposal for the parameters, typically a Gaussian random walk. However, this can lead to a poor exploration of the parameter space and an inefficient use of the generated particles. We propose a number of alternative versions of PMH that incorporate gradient and Hessian information about the posterior into the proposal. This information is more or less obtained as a byproduct of the likelihood estimation. Indeed, we show how to estimate the required information using a fixed-lag particle smoother, with a computational cost growing linearly in the number of particles. We conclude that the proposed methods can: (i) decrease the length of the burn-in phase, (ii) increase the mixing of the Markov chain at the stationary phase, and (iii) make the proposal distribution scale invariant which simplifies tuning.},
  pid = {J3},
}

@Article{LindstenJS:2014,
  author    = {Lindsten, Fredrik and Jordan, Michael I. and Sch\"on, Thomas B.},
  title     = {Particle {G}ibbs with Ancestor Sampling},
  journal   = jour_jmlr,
  year      = {2014},
  volume    = {15},
  pages     = {2145--2184},
  url = {http://jmlr.org/papers/v15/lindsten14a.html},
  abstract = {Particle Markov chain Monte Carlo (PMCMC) is a systematic way of combining the two main tools used for Monte Carlo statistical inference: sequential Monte Carlo (SMC) and Markov chain Monte Carlo (MCMC). We present a novel PMCMC algorithm that we refer to as particle Gibbs with ancestor sampling (PGAS). PGAS provides the data analyst with an off-the-shelf class of Markov kernels that can be used to simulate the typically high-dimensional and highly autocorrelated state trajectory in a state-space model. The ancestor sampling procedure enables fast mixing of the PGAS kernel even when using seemingly few particles in the underlying SMC sampler. This is important as it can significantly reduce the computational burden that is typically associated with using SMC. PGAS is conceptually similar to the existing PG with backward simulation (PGBS) procedure. Instead of using separate forward and backward sweeps as in PGBS, however, we achieve the same effect in a single forward sweep. This makes PGAS well suited for addressing inference problems not only in state-space models, but also in models with more complex dependencies, such as non-Markovian, Bayesian nonparametric, and general probabilistic graphical models.},
  pid   = {J2},
}



@Article{LindstenSJ:2013,
  author    = {Lindsten, Fredrik and Sch\"on, Thomas B. and Jordan, Michael I.},
  title     = {Bayesian semiparametric {W}iener system identification},
  journal   = jour_automatica,
  year      = {2013},
  volume    = {49},
  number    = {7},
  pages     = {2053--2063},
  doi = {10.1016/j.automatica.2013.03.021},
  abstract = {We present a novel method for Wiener system identification. The method relies on a semiparametric, i.e. a mixed parametric/nonparametric, model of a Wiener system. We use a state-space model for the linear dynamical system and a nonparametric Gaussian process model for the static nonlinearity. We avoid making strong assumptions, such as monotonicity, on the nonlinear mapping. Stochastic disturbances, entering both as measurement noise and as process noise, are handled in a systematic manner. The nonparametric nature of the Gaussian process allows us to handle a wide range of nonlinearities without making problem-specific parameterizations. We also consider sparsity-promoting priors, based on generalized hyperbolic distributions, to automatically infer the order of the underlying dynamical system. We derive an inference algorithm based on an efficient particle Markov chain Monte Carlo method, referred to as particle Gibbs with ancestor sampling. The method is profiled on two challenging identification problems with good results. Blind Wiener system identification is handled as a special case.},
  pid   = {J1},
}





@InProceedings{WidmannLZ:2021,
	title={Calibration tests beyond classification},
	author={David Widmann and Fredrik Lindsten and Dave Zachariah},
	booktitle={International Conference on Learning Representations},
	year={2021},
	url={https://openreview.net/forum?id=-bxf89v3Nx},
	note = {Forthcoming},
	pid      = {C45},	
}

@InCollection{NaessethLB:2020,
  author       = {Christian A. Naesseth and Fredrik Lindsten and David M. Blei},
  title        = {Markovian Score Climbing: Variational Inference with KL(p||q)},
  abstract     = {Modern variational inference (VI) uses stochastic gradients to avoid intractable expectations, enabling large-scale probabilistic inference in complex models. VI posits a family of approximating distributions q and then finds the member of that family that is closest to the exact posterior p. Traditionally, VI algorithms minimize the “exclusive Kullback-Leibler (KL)” KL(q||p), often for computational convenience. Recent research, however, has also focused on the “inclusive KL” KL(p||q), which has good statistical properties that makes it more appropriate for certain inference problems. This paper develops a simple algorithm for reliably minimizing the inclusive KL. Consider a valid Markov chain Monte Carlo (MCMC) method, a Markov chain whose stationary distribution is p. The algorithm we develop iteratively samples the chain, and then uses those samples to follow the score function of the variational approximation with a Robbins-Monro stepsize schedule. This method, which we call Markovian score climbing (MSC), converges to a local optimum of the inclusive KL. It does not suffer from the systematic errors inherent in existing methods, such as Reweighted Wake-Sleep and Neural Adaptive Sequential Monte Carlo, which lead to bias in their final estimates. In a variant that ties the variational approximation directly to the Markov chain, MSC further provides a new algorithm that melds VI and MCMC. We illustrate convergence on a toy model and demonstrate the utility of MSC on Bayesian probit regression for classification as well as a stochastic volatility model for financial data.},
  booktitle = {Advances in Neural Information Processing Systems 33},
  url = {https://arxiv.org/abs/2003.10374},  
  note = {Forthcoming},
  year         = {2020},   
  pid      = {C44},
}


@InProceedings{LindqvistOLS:2020,
  author       = {Jakob Lindqvist and Amanda Olmin and Fredrik Lindsten and Lennart Svensson},
  title        = {A general framework for ensemble distribution distillation},
  booktitle = PROC #{ 30th } # conf_mlsp, 
  url = {https://arxiv.org/abs/2002.11531},
  year         = {2020},
  address   = {Virtual Conference},
  month     = sep,  
  abstract = {Ensembles of neural networks have been shown to give better performance than single networks, both in terms of predictions and uncertainty estimation. Additionally, ensembles allow the uncertainty to be decomposed into aleatoric (data) and epistemic (model) components, giving a more complete picture of the predictive uncertainty. Ensemble distillation is the process of compressing an ensemble into a single model, often resulting in a leaner model that still outperforms the individual ensemble members. Unfortunately, standard distillation erases the natural uncertainty decomposition of the ensemble. We present a general framework for distilling both regression and classification ensembles in a way that preserves the decomposition. We demonstrate the desired behaviour of our framework and show that its predictive performance is on par with standard distillation.},
  pid      = {C43},
}

@InProceedings{SidenL:2020,
  author       = {Per Sidén and Fredrik Lindsten},
  title        = {Deep {G}aussian {M}arkov random fields},
  booktitle = PROC #{ 37th } # conf_icml, 
  url = {https://arxiv.org/abs/2002.07467},
  year         = {2020},
  address   = {Virtual Conference},
  month     = jul,  
  abstract = {Gaussian Markov random fields (GMRFs) are probabilistic graphical models widely used in spatial statistics and related fields to model dependencies over spatial structures. We establish a formal connection between GMRFs and convolutional neural networks (CNNs). Common GMRFs are special cases of a generative model where the inverse mapping from data to latent variables is given by a 1-layer linear CNN. This connection allows us to generalize GMRFs to multi-layer CNN architectures, effectively increasing the order of the corresponding GMRF in a way which has favorable computational scaling. We describe how well-established tools, such as autodiff and variational inference, can be used for simple and efficient inference and learning of the deep GMRF. We demonstrate the flexibility of the proposed model and show that it outperforms the state-of-the-art on a dataset of satellite temperatures, in terms of prediction and predictive uncertainty.},
  pid      = {C42},
}

@InProceedings{KudlickaMSL:2020,
  author    = {Jan Kudlicka and Lawrence M. Murray and Thomas B. Schön and Fredrik Lindsten},
  title     = {Particle filter with rejection control and unbiased estimator of the marginal likelihood},
  booktitle = PROC #{ 45th } # conf_icassp,
  address   = {Barcelona, Spain},
  year      = {2020},
  month 	= dec,
  url 		= {https://arxiv.org/abs/1910.09527},
  abstract  = {We consider the combined use of resampling and partial rejection control in sequential Monte Carlo methods, also known as particle filters. While the variance reducing properties of rejection control are known, there has not been (to the best of our knowledge) any work on unbiased estimation of the marginal likelihood (also known as the model evidence or the normalizing constant) in this type of particle filters. Being able to estimate the marginal likelihood without bias is highly relevant for model comparison, computation of interpretable and reliable confidence intervals, and in exact approximation methods, such as particle Markov chain Monte Carlo. In the paper we present a particle filter with rejection control that enables unbiased estimation of the marginal likelihood.},
  pid   = {C41},
}


@InCollection{WigrenRML:2019,
  author    = {Wigren, Anna and Risuleo, Riccardo Sven and Murray, Lawrence and Lindsten, Fredrik},
  title     = {Parameter elimination in particle {G}ibbs sampling},
  booktitle = {Advances in Neural Information Processing Systems 32},
  publisher = {Curran Associates, Inc.},
  year      = {2019},
  editor    = {H. Wallach and H. Larochelle and A. Beygelzimer and F. d\textquotesingle Alch\'{e}-Buc and E. Fox and R. Garnett},
  pages     = {8916--8927},
  abstract  = {Bayesian inference in state-space models is challenging due to high-dimensional state trajectories. A viable approach is particle Markov chain Monte Carlo (PMCMC), combining MCMC and sequential Monte Carlo to form exact approximations'' to otherwise-intractable MCMC methods. The performance of the approximation is limited to that of the exact method. We focus on particle Gibbs (PG) and particle Gibbs with ancestor sampling (PGAS), improving their performance beyond that of the ideal Gibbs sampler (which they approximate) by marginalizing out one or more parameters. This is possible when the parameter(s) has a conjugate prior relationship with the complete data likelihood. Marginalization yields a non-Markov model for inference, but we show that, in contrast to the general case, the methods still scale linearly in time. While marginalization can be cumbersome to implement, recent advances in probabilistic programming have enabled its automation. We demonstrate how the marginalized methods are viable as efficient inference backends in probabilistic programming, and demonstrate with examples in ecology and epidemiology.},
  comment = {NeurIPS Oral},
  pid   = {C40},
  url       = {http://papers.nips.cc/paper/9094-parameter-elimination-in-particle-gibbs-sampling},
}

@InCollection{WidmannLZ:2019,
  author    = {Widmann, David and Lindsten, Fredrik and Zachariah, Dave},
  title     = {Calibration tests in multi-class classification: A unifying framework},
  booktitle = {Advances in Neural Information Processing Systems 32},
  publisher = {Curran Associates, Inc.},
  year      = {2019},
  editor    = {H. Wallach and H. Larochelle and A. Beygelzimer and F. d\textquotesingle Alch\'{e}-Buc and E. Fox and R. Garnett},
  pages     = {12236--12246},
  abstract  = {In safety-critical applications a probabilistic model is usually required to be calibrated, i.e., to capture the uncertainty of its predictions accurately. In multi-class classification, calibration of the most confident predictions only is often not sufficient. We propose and study calibration measures for multi-class classification that generalize existing measures such as the expected calibration error, the maximum calibration error, and the maximum mean calibration error. We propose and evaluate empirically different consistent and unbiased estimators for a specific class of measures based on matrix-valued kernels. Importantly, these estimators can be interpreted as test statistics associated with well-defined bounds and approximations of the p-value under the null hypothesis that the model is calibrated, significantly improving the interpretability of calibration measures, which otherwise lack any meaningful unit or scale.},
  comment = {NeurIPS Spotlight},
  pid   = {C39},
  url       = {http://papers.nips.cc/paper/9392-calibration-tests-in-multi-class-classification-a-unifying-framework},
}

@InCollection{NemethLFH:2019,
  author    = {Nemeth, Christopher and Lindsten, Fredrik and Filippone, Maurizio and Hensman, James},
  title     = {Pseudo-Extended {M}arkov chain {M}onte {C}arlo},
  booktitle = {Advances in Neural Information Processing Systems 32},
  publisher = {Curran Associates, Inc.},
  year      = {2019},
  editor    = {H. Wallach and H. Larochelle and A. Beygelzimer and F. d\textquotesingle Alch\'{e}-Buc and E. Fox and R. Garnett},
  pages     = {4314--4324},
  abstract  = {Sampling from posterior distributions using Markov chain Monte Carlo (MCMC) methods can require an exhaustive number of iterations, particularly when the posterior is multi-modal as the MCMC sampler can become trapped in a local mode for a large number of iterations. In this paper, we introduce the pseudo-extended MCMC method as a simple approach for improving the mixing of the MCMC sampler for multi-modal posterior distributions. The pseudo-extended method augments the state-space of the posterior using pseudo-samples as auxiliary variables. On the extended space, the modes of the posterior are connected, which allows the MCMC sampler to easily move between well-separated posterior modes. We demonstrate that the pseudo-extended approach delivers improved MCMC sampling over the Hamiltonian Monte Carlo algorithm on multi-modal posteriors, including Boltzmann machines and models with sparsity-inducing priors.},
  pid   = {C38},
  url       = {https://papers.nips.cc/paper/8683-pseudo-extended-markov-chain-monte-carlo},
}

@InProceedings{UmenbergerSL:2019,
  author    = {Jack Umenberger and Thomas B. Schön and Fredrik Lindsten},
  title     = {Bayesian identification of state-space models via adaptive thermostats},
  booktitle = PROC #{ 58th } # conf_cdc,
  year      = {2019},
  address   = {Nice, France},
  month     = dec,
  pid   = {C37},
}

@InProceedings{VaicenaviciusWALRS:2019,
  author    = {Juozas Vaicenavicius and David Widmann and Carl Andersson and Fredrik Lindsten and Jacob Roll and Thomas B. Schön},
  title     = {Evaluating model calibration in classification},
  booktitle = PROC #{ 22nd } # conf_aistats,
  year      = {2019},
  address   = {Naha, Okinawa, Japan},
  month     = apr,
  pid   = {C36},
}

@InCollection{LindstenHV:2018,
  author    = {Lindsten, Fredrik and Helske, Jouni and Vihola, Matti},
  title     = {Graphical model inference: Sequential {M}onte {C}arlo meets deterministic approximations},
  booktitle = {Advances in Neural Information Processing Systems 31},
  publisher = {Curran Associates, Inc.},
  year      = {2018},
  editor    = {S. Bengio and H. Wallach and H. Larochelle and K. Grauman and N. Cesa-Bianchi and R. Garnett},
  pages     = {8190--8200},
  comment      = {NeurIPS Spotlight},
  pid   = {C35},
  url       = {http://papers.nips.cc/paper/8041-graphical-model-inference-sequential-monte-carlo-meets-deterministic-approximations.pdf},
}

@InProceedings{RisuleoLH:2018,
  author    = {Riccardo S. Risuleo and Fredrik Lindsten and Håkan Hjalmarsson},
  title     = {Semi-parametric kernel-based identification of {W}iener systems},
  booktitle = PROC #{ 57th } # conf_cdc,
  year      = {2018},
  address   = {Miami Beach, FL, USA},
  month     = dec,
  pid   = {C34},
}

@InProceedings{WigrenML:2018,
  author    = {Anna Wigren and Lawrence Murray and Fredrik Lindsten},
  title     = {Improving the particle filter in high dimensions using conjugate artificial process noise},
  booktitle = PROC #{ 18th } # conf_sysid,
  year      = {2018},
  address   = {Stockholm, Sweden},
  month     = jul,
  pid   = {C33},
}

@InProceedings{SvenssonLS:2018,
  author    = {Andreas Svensson and Fredrik Lindsten and Thomas B. Schön},
  title     = {Learning Nonlinear State-Space Models Using Smooth Particle-Filter-Based Likelihood Approximations},
  booktitle = PROC #{ 18th } # conf_sysid,
  year      = {2018},
  address   = {Stockholm, Sweden},
  month     = jul,
  pid   = {C32},
}

@InProceedings{RainforthNLPMDW:2016,
  author    = {Tom Rainforth and Christian A. Naesseth and Fredrik Lindsten and Brooks Paige and Jan-Willem van de Meent and Arnaud Doucet and Frank Wood},
  title     = {Interacting Particle {M}arkov Chain {M}onte Carlo},
  booktitle = PROC #{ 33rd } # conf_icml,
  year      = {2016},
  address   = {New York, USA},
  month     = jun,
  pid   = {C31},
}

@InProceedings{WagbergLS:2015,
  author    = {Johan Wågberg and Fredrik Lindsten and Thomas B. Schön},
  title     = {Bayesian nonparametric identification of piecewise affine {ARX} systems},
  booktitle = PROC #{ 17th } # conf_sysid,
  year      = {2015},
  address   = {Beijing, China},
  month     = oct,
  pid   = {C30},
}

@InProceedings{DahlinLS:2015a,
  author    = {Johan Dahlin and Fredrik Lindsten and Thomas B. Schön},
  title     = {Quasi-{N}ewton particle {M}etropolis-{H}astings applied to intractable likelihood models},
  booktitle = PROC #{ 17th } # conf_sysid,
  year      = {2015},
  address   = {Beijing, China},
  month     = oct,
  pid   = {C29},
}

@InProceedings{RiabizLG:2015,
  author    = {Marina Riabiz and Fredrik Lindsten and Simon J. Godsill},
  title     = {Pseudo-Marginal {MCMC} for Parameter Estimation in Alpha-Stable Distributions},
  booktitle = PROC #{ 17th } # conf_sysid,
  year      = {2015},
  address   = {Beijing, China},
  month     = oct,
  pid   = {C28},
}

@InProceedings{SchonLDWNSD:2105,
  author    = {Thomas B. Schön and Fredrik Lindsten and Johan Dahlin and Johan Wågberg and Christian A. Naesseth and Andreas Svensson and Liang Dai},
  title     = {Sequential {M}onte {C}arlo Methods for System Identification},
  booktitle = PROC #{ 17th } # conf_sysid,
  year      = {2015},
  address   = {Beijing, China},
  month     = oct,
  pid   = {C27},
}

@InProceedings{NaessethLS:2015,
  author       = {Naesseth, Christian A. and Lindsten, Fredrik and Sch\"on, Thomas B.},
  title        = {Nested Sequential {M}onte {C}arlo Methods},
  booktitle    = PROC #{ 32nd International Conference on Machine Learning (ICML)},
  year         = {2015},
  address      = {Lille, France},
  month        = jul,
  pid      = {C26},
  howpublished = {arXiv.org, arXiv:1502.02536},
  owner        = {lindsten},
  timestamp    = {2015.03.13},
}

@InProceedings{Lacoste-JulienLB:2015,
  author    = {Simon Lacoste-Julien and Fredrik Lindsten and Francis Bach},
  title     = {Sequential Kernel Herding: {F}rank-{W}olfe Optimization for Particle Filtering},
  booktitle = PROC #{ 18th } # conf_aistats,
  year      = {2015},
  address   = {San Diego, USA},
  month     = may,
  pid   = {C25},
}

@InProceedings{BunchLS:2015,
  author    = {Bunch, Pete and Lindsten, Fredrik and Singh, Sumeetpal S.},
  title     = {Particle {G}ibbs with refreshed backward simulation},
  booktitle = PROC #{ 40th } # conf_icassp,
  year      = {2015},
  address   = {Brisbane, Australia},
  month     = apr,
  pid   = {C24},
  owner     = {lindsten},
  timestamp = {2014.11.26},
}

@InCollection{NaessethLS:2014,
  author    = {Naesseth, Christian A. and Lindsten, Fredrik and Sch\"on, Thomas B.},
  title     = {Sequential {M}onte {C}arlo for graphical models},
  booktitle = collection_nips #{ 27},
  year      = {2014},
  pages     = {1862--1870},
  pid   = {C23},
  owner     = {lindsten},
  timestamp = {2014-02-18},
  url       = {https://papers.nips.cc/paper/5570-sequential-monte-carlo-for-graphical-models},
}

@InProceedings{NaessethLS:2014a,
  author    = {Christian A. Naesseth and Fredrik Lindsten and Thomas B. Schön},
  title     = {Capacity estimation of two-dimensional channels using Sequential {M}onte {C}arlo},
  booktitle = PROC #{ 2014 IEEE Information Theory Workshop (ITW)},
  year      = {2014},
  address   = {Hobart, Tasmania},
  month     = nov,
  pid   = {C22},
}

@InProceedings{SvenssonLS:2014,
  author    = {Svensson, Andreas and Lindsten, Fredrik and Sch\"on, Thomas B.},
  title     = {Identification of jump {M}arkov linear models using particle filters},
  booktitle = PROC #{ 53rd } # conf_cdc,
  year      = {2014},
  address   = {Los Angeles, USA},
  month     = dec,
  pid   = {C21},
  owner     = {lindsten},
  timestamp = {2014.09.02},
}

@InProceedings{FrigolaLSR:2014,
  author    = {Frigola, Roger and Lindsten, Fredrik and Sch\"on, Thomas B. and Rasmussen, Carl E.},
  title     = {Identification of {G}aussian Process State-Space Models with Particle Stochastic Approximation {EM}},
  booktitle = PROC #{ 19th } # conf_ifacwc,
  year      = {2014},
  address   = {Cape Town, South Africa},
  month     = aug,
  pid   = {C20},
  owner     = {lindsten},
  timestamp = {2014.02.19},
}

@InProceedings{DahlinL:2014,
  author    = {Dahlin, Johan and Lindsten, Fredrik},
  title     = {Particle filter-based {G}aussian Process Optimisation for Parameter Inference},
  booktitle = PROC #{ 19th } # conf_ifacwc,
  year      = {2014},
  address   = {Cape Town, South Africa},
  month     = aug,
  pid   = {C19},
  owner     = {lindsten},
  timestamp = {2014.02.13},
}

@InProceedings{DahlinLS:2014,
  author    = {Dahlin, Johan and Lindsten, Fredrik and Sch\"on, Thomas B.},
  title     = {Second-order Particle {MCMC} for {B}ayesian Parameter Inference},
  booktitle = PROC #{ 19th } # conf_ifacwc,
  year      = {2014},
  address   = {Cape Town, South Africa},
  month     = aug,
  pid   = {C18},
  owner     = {lindsten},
  timestamp = {2014.02.13},
}

@InProceedings{GunnarssonLC:2014,
  author    = {Fredrik Gunnarsson and Fredrik Lindsten and Niclas Carlsson},
  title     = {Particle Filtering for Network-Based Positioning Terrestrial Radio Networks},
  booktitle = PROC #{ IET Conference on Data Fusion and Target Tracking},
  year      = {2014},
  address   = {Liverpool, UK},
  comment   = {ISIF Best Paper Award},
  pid   = {C17},
}

@InCollection{FrigolaLSR:2013,
  author    = {Frigola, Roger and Lindsten, Fredrik and Sch\"on, Thomas B. and Rasmussen, Carl E.},
  title     = {{B}ayesian Inference and Learning in {G}aussian Process State-Space Models with Particle {MCMC}},
  booktitle = collection_nips #{ 26},
  year      = {2013},
  month     = dec,
  pid   = {C16},
  owner     = {lindsten},
  timestamp = {2013.12.03},
}

@InProceedings{Lindsten:2013a,
  author    = {Lindsten, Fredrik},
  title     = {An efficient stochastic approximation {EM} algorithm using conditional particle filters},
  booktitle = PROC #{ 38th } # conf_icassp,
  year      = {2013},
  address   = {Vancouver, Canada},
  month     = may,
  pid   = {C15},
  owner     = {lindsten},
  timestamp = {2012.12.17},
}

@InProceedings{DahlinLS:2013,
  author    = {Dahlin, Johan and Lindsten, Fredrik and Sch\"on, Thomas B.},
  title     = {Particle {M}etropolis {H}astings using {L}angevin dynamics},
  booktitle = PROC #{ 38th } # conf_icassp,
  year      = {2013},
  address   = {Vancouver, Canada},
  month     = may,
  pid   = {C14},
  owner     = {lindsten},
  timestamp = {2013.06.17},
}

@InProceedings{LindstenBGS:2013,
  author    = {Lindsten, Fredrik and Bunch, Pete and Godsill, Simon J. and Sch\"on, Thomas B.},
  title     = {Rao-{B}lackwellized particle smoothers for mixed linear/nonlinear state-space models},
  booktitle = PROC #{ 38th } # conf_icassp,
  year      = {2013},
  address   = {Vancouver, Canada},
  month     = may,
  pid   = {C13},
  owner     = {lindsten},
  timestamp = {2012.12.08},
}

@InProceedings{TaghaviLSS:2013,
  author    = {Taghavi, Ehsan and Lindsten, Fredrik and Svensson, Lennart and Sch\"on, Thomas B.},
  title     = {Adaptive stopping for fast particle smoothing},
  booktitle = PROC #{ 38th } # conf_icassp,
  year      = {2013},
  address   = {Vancouver, Canada},
  month     = may,
  pid   = {C12},
  owner     = {lindsten},
  timestamp = {2012.12.08},
}

@InCollection{LindstenJS:2012,
  author    = {Lindsten, Fredrik and Jordan, Michael I. and Sch\"on, Thomas B.},
  title     = {Ancestor Sampling for Particle {G}ibbs},
  booktitle = collection_nips #{ 25},
  year      = {2012},
  editor    = {Bartlett, P. and Pereira, F. C. N. and Burges, C. J. C. and Bottou, L. and Weinberger, K. Q.},
  pages     = {2600--2608},
  pid   = {C11},
  owner     = {lindsten},
  timestamp = {2013.06.25},
}

@InProceedings{LindstenSJ:2012,
  author    = {Lindsten, Fredrik and Sch\"on, Thomas B. and Jordan, Michael I.},
  title     = {A semiparametric {B}ayesian approach to {W}iener system identification},
  booktitle = PROC #{ 16th } # conf_sysid,
  year      = {2012},
  address   = {Brussels, Belgium},
  month     = jul,
  pid   = {C10},
  owner     = {lindsten},
  timestamp = {2011.12.01},
}

@InProceedings{LindstenSS:2012,
  author    = {Lindsten, Fredrik and Sch\"on, Thomas B. and Svensson, Lennart},
  title     = {A non-degenerate {R}ao-{B}lack\-wellised particle filter for estimating static parameters in dynamical models},
  booktitle = PROC #{ 16th } # conf_sysid,
  year      = {2012},
  address   = {Brussels, Belgium},
  month     = jul,
  pid   = {C9},
  owner     = {lindsten},
  timestamp = {2013.06.17},
}

@InProceedings{DahlinLSW:2012,
  author    = {Dahlin, Johan and Lindsten, Fredrik and Sch\"on, Thomas B. and Wills, Adrian},
  title     = {Hierarchical {B}ayesian {ARX} models for robust inference},
  booktitle = PROC #{ 16th } # conf_sysid,
  year      = {2012},
  address   = {Brussels, Belgium},
  month     = jul,
  pid   = {C8},
  owner     = {lindsten},
  timestamp = {2013.06.17},
}

@InProceedings{WillsSLN:2012,
  author    = {Wills, Adrian and Sch\"on, Thomas B. and Lindsten, Fredrik and Ninness, Brett},
  title     = {Estimation of Linear Systems using a {G}ibbs Sampler},
  booktitle = PROC #{ 16th } # conf_sysid,
  year      = {2012},
  address   = {Brussels, Belgium},
  month     = jul,
  pid   = {C7},
  owner     = {lindsten},
  timestamp = {2011.12.01},
}

@InProceedings{LindstenS:2012,
  author    = {Lindsten, Fredrik and Sch\"{o}n, Thomas B.},
  title     = {On the use of backward simulation in the particle {G}ibbs sampler},
  booktitle = PROC #{ 37th } # conf_icassp,
  year      = {2012},
  address   = {Kyoto, Japan},
  month     = mar,
  pid   = {C6},
  owner     = {lindsten},
  timestamp = {2011.10.04},
}

@InProceedings{LindstenOL:2011,
  author    = {Lindsten, Fredrik and Ohlsson, Henrik and Ljung, Lennart},
  title     = {Clustering using sum-of-norms regularization; with application to particle filter output computation},
  booktitle = PROC #{ } # conf_ssp,
  year      = {2011},
  address   = {Nice, France},
  month     = jun,
  pid   = {C5},
  owner     = {lindsten},
  timestamp = {2011.02.07},
}

@InProceedings{LindstenSO:2011,
  author    = {Lindsten, Fredrik and Sch\"on, Thomas B. and Olsson, Jimmy},
  title     = {An explicit variance reduction expression for the {R}ao-{B}lackwellised particle filter},
  booktitle = PROC #{ 18th } # conf_ifacwc,
  year      = {2011},
  address   = {Milan, Italy},
  month     = aug,
  pid   = {C4},
  owner     = {lindsten},
  timestamp = {2011.03.17},
}

@InProceedings{LindstenS:2010a,
  author    = {Lindsten, Fredrik and Sch\"{o}n, Thomas B.},
  title     = {Identification of Mixed Linear/Nonlinear State-Space Models},
  booktitle = PROC #{ 49th } # conf_cdc,
  year      = {2010},
  address   = {Atlanta, USA},
  month     = dec,
  pid   = {C3},
  owner     = {lindsten},
  timestamp = {2010.07.06},
}

@InProceedings{LindstenCOTSG:2010,
  author    = {Lindsten, Fredrik and Callmer, Jonas and Ohlsson, Henrik and T{\"{o}}rnqvist, David and Sch{\"{o}}n, Thomas B. and Gustafsson, Fredrik},
  title     = {Geo-referencing for {UAV} Navigation using Environmental Classification},
  booktitle = PROC #{ } # conf_icra,
  year      = {2010},
  address   = {Anchorage, USA},
  month     = May,
  pid   = {C2},
}

@InProceedings{LindstenNG:2009,
  author    = {Lindsten, Fredrik and Nordlund, Per-Johan and Gustafsson, Fredrik},
  title     = {Conflict Detection Metrics for Aircraft Sense and Avoid Systems},
  booktitle = PROC #{7th } # conf_safeprocess,
  year      = {2009},
  address   = {Barcelona, Spain},
  month     = Jul,
  pid   = {C1},
}


@PhdThesis{Lindsten:2013,
  author    = {Lindsten, Fredrik},
  title     = {Particle Filters and Markov Chains for Learning of Dynamical Systems},
  school    = ISYname,
  year      = {2013},
  type      = {Linköping Studies in Science and Technology. Dissertations, No. 1530},
  address   = {SE-581 83 Link{\"o}ping, Sweden},
  month     = oct,
  pid   = {PhD},
}

@PhdThesis{Lindsten:2011,
  author    = {Lindsten, Fredrik},
  title     = {Rao-{B}lackwellised particle methods for inference and identification},
  school    = ISYname,
  year      = {2011},
  type      = {Licentiate Thesis no. 1480},
  address   = {SE-581 83 Link{\"o}ping, Sweden},
  month     = jun,
  pid   = {Lic},
}


@Comment{jabref-meta: databaseType:bibtex;}
